{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = Word2Vec.load(\"word2vec.model\").wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KMeans(n_clusters=2, max_iter=1000, random_state=True, n_init=50).fit(X=word_vectors.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ingrahamangle', 0.9867069721221924),\n",
       " ('places', 0.985238790512085),\n",
       " ('rob', 0.9845202565193176),\n",
       " ('warrior', 0.9817732572555542),\n",
       " ('level', 0.9817361831665039),\n",
       " ('written', 0.9810543656349182),\n",
       " ('cared', 0.9797549247741699),\n",
       " ('brainwashed', 0.9791715741157532),\n",
       " ('grab', 0.9788890480995178),\n",
       " ('tie', 0.9780217409133911)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_vector(model.cluster_centers_[0], topn=10, restrict_vocab=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_cluster_center = model.cluster_centers_[0]\n",
    "negative_cluster_center = model.cluster_centers_[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = pd.DataFrame(word_vectors.vocab.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "words.columns = ['words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "words['vectors'] = words.words.apply(lambda x: word_vectors.wv[f'{x}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "words['cluster'] = words.vectors.apply(lambda x: model.predict([np.array(x)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "words.cluster = words.cluster.apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "words['cluster_value'] = [1 if i==0 else -1 for i in words.cluster]\n",
    "words['closeness_score'] = words.apply(lambda x: 1/(model.transform([x.vectors]).min()), axis=1)\n",
    "words['sentiment_coeff'] = words.closeness_score * words.cluster_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>vectors</th>\n",
       "      <th>cluster</th>\n",
       "      <th>cluster_value</th>\n",
       "      <th>closeness_score</th>\n",
       "      <th>sentiment_coeff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alllivesmatter</td>\n",
       "      <td>[0.016699448, -0.08501823, -0.05545717, -0.017...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.068106</td>\n",
       "      <td>1.068106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>r</td>\n",
       "      <td>[0.035080217, -0.03075597, -0.028907169, 0.031...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.220581</td>\n",
       "      <td>-1.220581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>look_like</td>\n",
       "      <td>[0.056356367, -0.1736919, -0.07211555, 0.00328...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.967770</td>\n",
       "      <td>3.967770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>attendant</td>\n",
       "      <td>[-0.013022023, -0.085772924, 0.030868307, 0.00...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.400982</td>\n",
       "      <td>-1.400982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>realdonaldtrump</td>\n",
       "      <td>[0.07376418, -0.08495202, -0.013488546, 0.0041...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.121306</td>\n",
       "      <td>1.121306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>graduates</td>\n",
       "      <td>[0.003774301, -0.11876246, -0.010919656, 0.043...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.312251</td>\n",
       "      <td>1.312251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>but</td>\n",
       "      <td>[0.07127262, -0.09853834, -0.03800298, 0.04171...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.951863</td>\n",
       "      <td>1.951863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>deranged</td>\n",
       "      <td>[0.05991525, -0.14158489, -0.019423803, 0.0311...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.742834</td>\n",
       "      <td>2.742834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ignorant</td>\n",
       "      <td>[0.053411055, -0.14167948, -0.052140776, 0.024...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.914238</td>\n",
       "      <td>2.914238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>incompetent</td>\n",
       "      <td>[0.07242316, -0.14452453, -0.059909265, 0.0361...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.372976</td>\n",
       "      <td>2.372976</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             words                                            vectors  \\\n",
       "0   alllivesmatter  [0.016699448, -0.08501823, -0.05545717, -0.017...   \n",
       "1                r  [0.035080217, -0.03075597, -0.028907169, 0.031...   \n",
       "2        look_like  [0.056356367, -0.1736919, -0.07211555, 0.00328...   \n",
       "3        attendant  [-0.013022023, -0.085772924, 0.030868307, 0.00...   \n",
       "4  realdonaldtrump  [0.07376418, -0.08495202, -0.013488546, 0.0041...   \n",
       "5        graduates  [0.003774301, -0.11876246, -0.010919656, 0.043...   \n",
       "6              but  [0.07127262, -0.09853834, -0.03800298, 0.04171...   \n",
       "7         deranged  [0.05991525, -0.14158489, -0.019423803, 0.0311...   \n",
       "8         ignorant  [0.053411055, -0.14167948, -0.052140776, 0.024...   \n",
       "9      incompetent  [0.07242316, -0.14452453, -0.059909265, 0.0361...   \n",
       "\n",
       "   cluster  cluster_value  closeness_score  sentiment_coeff  \n",
       "0        0              1         1.068106         1.068106  \n",
       "1        1             -1         1.220581        -1.220581  \n",
       "2        0              1         3.967770         3.967770  \n",
       "3        1             -1         1.400982        -1.400982  \n",
       "4        0              1         1.121306         1.121306  \n",
       "5        0              1         1.312251         1.312251  \n",
       "6        0              1         1.951863         1.951863  \n",
       "7        0              1         2.742834         2.742834  \n",
       "8        0              1         2.914238         2.914238  \n",
       "9        0              1         2.372976         2.372976  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "words[['words', 'sentiment_coeff']].to_csv('sentiment_dictionary.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_file = pd.read_csv('cleaned_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_map = pd.read_csv('sentiment_dictionary.csv')\n",
    "sentiment_dict = dict(zip(sentiment_map.words.values, sentiment_map.sentiment_coeff.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting tfidf scores of words in every sentence, and replacing them with their associated tfidf weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_weighting = final_file.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:507: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer=lambda y: y.split(), norm=None)\n",
    "tfidf.fit(file_weighting.full_text)\n",
    "features = pd.Series(tfidf.get_feature_names())\n",
    "transformed = tfidf.transform(file_weighting.full_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replacing words in sentences with their tfidf scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tfidf_dictionary(x, transformed_file, features):\n",
    "    '''\n",
    "    create dictionary for each input sentence x, where each word has assigned its tfidf score\n",
    "    \n",
    "    inspired  by function from this wonderful article: \n",
    "    https://medium.com/analytics-vidhya/automated-keyword-extraction-from-articles-using-nlp-bfd864f41b34\n",
    "    \n",
    "    x - row of dataframe, containing sentences, and their indexes,\n",
    "    transformed_file - all sentences transformed with TfidfVectorizer\n",
    "    features - names of all words in corpus used in TfidfVectorizer\n",
    "\n",
    "    '''\n",
    "    vector_coo = transformed_file[x.name].tocoo()\n",
    "    vector_coo.col = features.iloc[vector_coo.col].values\n",
    "    dict_from_coo = dict(zip(vector_coo.col, vector_coo.data))\n",
    "    return dict_from_coo\n",
    "\n",
    "def replace_tfidf_words(x, transformed_file, features):\n",
    "    '''\n",
    "    replacing each word with it's calculated tfidf dictionary with scores of each word\n",
    "    x - row of dataframe, containing sentences, and their indexes,\n",
    "    transformed_file - all sentences transformed with TfidfVectorizer\n",
    "    features - names of all words in corpus used in TfidfVectorizer\n",
    "    '''\n",
    "    dictionary = create_tfidf_dictionary(x, transformed_file, features)   \n",
    "    return list(map(lambda y:dictionary[f'{y}'], x.full_text.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 32.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "replaced_tfidf_scores = file_weighting.apply(lambda x: replace_tfidf_words(x, transformed, features), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_sentiment_words(word, sentiment_dict):\n",
    "    '''\n",
    "    replacing each word with its associated sentiment score from sentiment dict\n",
    "    '''\n",
    "    try:\n",
    "        out = sentiment_dict[word]\n",
    "    except KeyError:\n",
    "        out = 0\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "replaced_closeness_scores = file_weighting.full_text.apply(lambda x: list(map(lambda y: replace_sentiment_words(y, sentiment_dict), x.split())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging both previous steps and getting the predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        1\n",
      "1        1\n",
      "2        1\n",
      "3        1\n",
      "4        1\n",
      "        ..\n",
      "35688    1\n",
      "35689    1\n",
      "35690    0\n",
      "35691    1\n",
      "35692    1\n",
      "Name: prediction, Length: 35693, dtype: int8 0                                  traceybr alllivesmatter\n",
      "1                     r look_like easyjet_flight attendant\n",
      "2                                         r alllivesmatter\n",
      "3        r liev alllivesmatter alllivesmatter alllivesm...\n",
      "4        realdonaldtrump congrats graduates but embarra...\n",
      "                               ...                        \n",
      "35688    r minor point but counter counter racism prote...\n",
      "35689      r jaimetoons good work twitter blacklivesmatter\n",
      "35690    moh scandals lkwyt_lg mnsb_nwb lqbyl2_jml swrh...\n",
      "35691          r not saying others saying blacklivesmatter\n",
      "35692    inspiring real_president take stage presidentb...\n",
      "Name: sentence, Length: 35693, dtype: object\n"
     ]
    }
   ],
   "source": [
    "replacement_df = pd.DataFrame(data=[replaced_closeness_scores, replaced_tfidf_scores, file_weighting.full_text]).T\n",
    "replacement_df.columns = ['sentiment_coeff', 'tfidf_scores', 'sentence']\n",
    "replacement_df['sentiment_rate'] = replacement_df.apply(lambda x: np.array(x.loc['sentiment_coeff']) @ np.array(x.loc['tfidf_scores']), axis=1)\n",
    "replacement_df['prediction'] = (replacement_df.sentiment_rate>0).astype('int8')\n",
    "print(replacement_df['prediction'],replacement_df['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = [replacement_df,final_file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dataframe = pd.concat(dataframes, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dataframe[['full_text','prediction','hashtags']].to_csv('final_prediction.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
